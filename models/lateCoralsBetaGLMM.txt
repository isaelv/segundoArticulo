
model{
#1A. Diffuse normal priors for betas
for(i in 1:K){beta[i] ~ dnorm(0, 0.0001)}
#1B. Normal priors for random effects
for(i in 1:Nre) {a[i] ~ dnorm(0, tau)}
#1C. half-Cauchy(25) prior for sigma zoo
num ~ dnorm(0, 0.0016)
denom ~ dnorm(0, 1)
sigma <- abs(num/denom)
tau <- 1/(sigma * sigma)
#1D. half-Cauchy(25) prior for tau
numtheta ~ dnorm(0, 0.0016)
denomtheta ~ dnorm(0, 1)
theta <- abs(numtheta/denomtheta)
#2. Likelihood
for(i in 1:N){
Y[i] ~ dbeta(shape1[i], shape2[i])
shape1[i] <- theta * pi[i]
shape2[i] <- theta * (1 - pi[i])
logit(pi[i]) <- eta[i]
eta[i] <- inprod(beta[], X[i,]) + a[re[i]]
#Pearson residuals
ExpY[i] <- pi[i]
VarY[i] <- pi[i] * (1 - pi[i]) / (theta + 1)
PRes[i] <- (Y[i] - ExpY[i]) / sqrt(VarY[i])
#3. Discrepancy measures
YNew[i] ~ dbeta(shape1[i], shape2[i])
PResNew[i] <- (YNew[i] - ExpY[i]) / sqrt(VarY[i])
D[i] <- pow(PRes[i], 2)
DNew[i] <- pow(PResNew[i], 2)
}
Fit <- sum(D[1:N])
FitNew <- sum(DNew[1:N])
}
